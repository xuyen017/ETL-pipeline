{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 5.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: fe96489a-3af3-4479-8e0e-4cffc39f32ea\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\nWaiting for session fe96489a-3af3-4479-8e0e-4cffc39f32ea to get into ready status...\nSession fe96489a-3af3-4479-8e0e-4cffc39f32ea has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "dyf = glueContext.create_dynamic_frame.from_catalog(database='etl-project-for-database', table_name='raw_data')\ndyf.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "df = dyf.toDF()\ndf.show(10)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----+----------+----------+--------------+------+-------+--------+-----------+-------+--------+---------+---------------+---------------+----------------+------------+-----------------+---------------+-------------------+-----------------+-----------------+------------+------------+------------+------------+------------+--------+-------------+---------+--------+\n|  id|year_birth| education|marital_status|income|kidhome|teenhome|dt_customer|recency|mntwines|mntfruits|mntmeatproducts|mntfishproducts|mntsweetproducts|mntgoldprods|numdealspurchases|numwebpurchases|numcatalogpurchases|numstorepurchases|numwebvisitsmonth|acceptedcmp3|acceptedcmp4|acceptedcmp5|acceptedcmp1|acceptedcmp2|complain|z_costcontact|z_revenue|response|\n+----+----------+----------+--------------+------+-------+--------+-----------+-------+--------+---------+---------------+---------------+----------------+------------+-----------------+---------------+-------------------+-----------------+-----------------+------------+------------+------------+------------+------------+--------+-------------+---------+--------+\n|5524|      1957|Graduation|        Single| 58138|      0|       0| 2012-09-04|     58|     635|       88|            546|            172|              88|          88|                3|              8|                 10|                4|                7|           0|           0|           0|           0|           0|       0|            3|       11|       1|\n|2174|      1954|Graduation|        Single| 46344|      1|       1| 2014-03-08|     38|      11|        1|              6|              2|               1|           6|                2|              1|                  1|                2|                5|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n|4141|      1965|Graduation|      Together| 71613|      0|       0| 2013-08-21|     26|     426|       49|            127|            111|              21|          42|                1|              8|                  2|               10|                4|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n|6182|      1984|Graduation|      Together| 26646|      1|       0| 2014-02-10|     26|      11|        4|             20|             10|               3|           5|                2|              2|                  0|                4|                6|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n|5324|      1981|       PhD|       Married| 58293|      1|       0| 2014-01-19|     94|     173|       43|            118|             46|              27|          15|                5|              5|                  3|                6|                5|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n|7446|      1967|    Master|      Together| 62513|      0|       1| 2013-09-09|     16|     520|       42|             98|              0|              42|          14|                2|              6|                  4|               10|                6|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n| 965|      1971|Graduation|      Divorced| 55635|      0|       1| 2012-11-13|     34|     235|       65|            164|             50|              49|          27|                4|              7|                  3|                7|                6|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n|6177|      1985|       PhD|       Married| 33454|      1|       0| 2013-05-08|     32|      76|       10|             56|              3|               1|          23|                2|              4|                  0|                4|                8|           0|           0|           0|           0|           0|       0|            3|       11|       0|\n|4855|      1974|       PhD|      Together| 30351|      1|       0| 2013-06-06|     19|      14|        0|             24|              3|               3|           2|                1|              3|                  0|                2|                9|           0|           0|           0|           0|           0|       0|            3|       11|       1|\n|5899|      1950|       PhD|      Together|  5648|      1|       1| 2014-03-13|     68|      28|        0|              6|              1|               1|          13|                1|              1|                  0|                0|               20|           1|           0|           0|           0|           0|       0|            3|       11|       0|\n+----+----------+----------+--------------+------+-------+--------+-----------+-------+--------+---------+---------------+---------------+----------------+------------+-----------------+---------------+-------------------+-----------------+-----------------+------------+------------+------------+------------+------------+--------+-------------+---------+--------+\nonly showing top 10 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Drop columns that we don't need it\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "df = df[\"id\",\"year_birth\",\"education\",\"marital_status\",\"income\",\"dt_customer\"]\ndf.show(10)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----+----------+----------+--------------+------+-----------+\n|  id|year_birth| education|marital_status|income|dt_customer|\n+----+----------+----------+--------------+------+-----------+\n|5524|      1957|Graduation|        Single| 58138| 2012-09-04|\n|2174|      1954|Graduation|        Single| 46344| 2014-03-08|\n|4141|      1965|Graduation|      Together| 71613| 2013-08-21|\n|6182|      1984|Graduation|      Together| 26646| 2014-02-10|\n|5324|      1981|       PhD|       Married| 58293| 2014-01-19|\n|7446|      1967|    Master|      Together| 62513| 2013-09-09|\n| 965|      1971|Graduation|      Divorced| 55635| 2012-11-13|\n|6177|      1985|       PhD|       Married| 33454| 2013-05-08|\n|4855|      1974|       PhD|      Together| 30351| 2013-06-06|\n|5899|      1950|       PhD|      Together|  5648| 2014-03-13|\n+----+----------+----------+--------------+------+-----------+\nonly showing top 10 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Check NaN values for each column\n",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import *\n\ndf.select([count(when(col(c).isNull(),c)).alias(c) for c in df.columns]).show()",
			"metadata": {
				"tags": [],
				"editable": true,
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+----------+---------+--------------+------+-----------+\n| id|year_birth|education|marital_status|income|dt_customer|\n+---+----------+---------+--------------+------+-----------+\n|  0|         0|        0|             0|    24|          0|\n+---+----------+---------+--------------+------+-----------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "There are 24 NaN values in \"income\" column. Let's fill NaN values with mean.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Calculate the mean value of the column\nmean_value = df.select(mean(col('income'))).collect()[0][0]\n\n# Fill missing values with the mean value\ndf = df.fillna(mean_value, subset=['income'])\n\n# Check\ndf.select([count(when(col(c).isNull(),c)).alias(c) for c in df.columns]).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+----------+---------+--------------+------+-----------+\n| id|year_birth|education|marital_status|income|dt_customer|\n+---+----------+---------+--------------+------+-----------+\n|  0|         0|        0|             0|     0|          0|\n+---+----------+---------+--------------+------+-----------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Write the data to our S3 Bucket named \"transformed_data\" as csv.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df.write \\\n    .format(\"csv\") \\\n    .mode(\"append\") \\\n    .option(\"header\", \"true\") \\\n    .save(\"s3://etl-bucket-s3/etl-bucket-s3-database/transformed_data/\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Write the data to our S3 Bucket named \"transformed_data\" as json.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df.write \\\n    .format(\"json\") \\\n    .mode(\"append\") \\\n    .save(\"s3://etl-project-for-medium/etl-project-for-medium-database/transformed_data/\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		}
	]
}